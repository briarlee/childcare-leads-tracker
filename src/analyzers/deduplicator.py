"""
å»é‡æ¨¡å—
è´Ÿè´£æ£€æµ‹å’Œè¿‡æ»¤é‡å¤è®°å½•
"""

from typing import Dict, List, Set
from fuzzywuzzy import fuzz

from utils.logger import get_logger
from utils.helpers import generate_record_id


class Deduplicator:
    """å»é‡å¤„ç†å™¨"""
    
    # åœ°å€ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆ0-100ï¼‰
    ADDRESS_SIMILARITY_THRESHOLD = 90
    
    def __init__(self, sheets_manager=None):
        """
        åˆå§‹åŒ–å»é‡å™¨
        
        Args:
            sheets_manager: SheetsManagerå®ä¾‹ï¼Œç”¨äºè·å–å†å²æ•°æ®
        """
        self.logger = get_logger()
        self.sheets_manager = sheets_manager
        
        # ç¼“å­˜å·²å­˜åœ¨çš„æ•°æ®
        self._existing_licenses: Set[str] = set()
        self._existing_addresses: Set[str] = set()
        self._initialized = False
    
    def _load_existing_data(self):
        """ä»Google SheetsåŠ è½½å·²å­˜åœ¨çš„æ•°æ®"""
        if self._initialized or self.sheets_manager is None:
            return
        
        try:
            self.logger.info("ğŸ“‚ åŠ è½½å†å²æ•°æ®ç”¨äºå»é‡...")
            
            # è·å–å·²å­˜åœ¨çš„è®¸å¯è¯å·
            self._existing_licenses = self.sheets_manager.get_existing_license_numbers()
            self.logger.info(f"   å·²åŠ è½½ {len(self._existing_licenses)} ä¸ªè®¸å¯è¯å·")
            
            # è·å–å·²å­˜åœ¨çš„åœ°å€
            self._existing_addresses = self.sheets_manager.get_existing_addresses()
            self.logger.info(f"   å·²åŠ è½½ {len(self._existing_addresses)} ä¸ªåœ°å€")
            
            self._initialized = True
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ åŠ è½½å†å²æ•°æ®å¤±è´¥: {str(e)}")
            self._initialized = True  # é¿å…é‡å¤å°è¯•
    
    def remove_duplicates(self, records: List[Dict]) -> List[Dict]:
        """
        ç§»é™¤é‡å¤è®°å½•
        
        å»é‡é€»è¾‘ä¼˜å…ˆçº§ï¼š
        1. è®¸å¯è¯å·å®Œå…¨åŒ¹é…
        2. åœ°å€+åç§°ç»„åˆå®Œå…¨åŒ¹é…
        3. åœ°å€æ¨¡ç³ŠåŒ¹é…ï¼ˆç›¸ä¼¼åº¦>90%ï¼‰
        
        Args:
            records: åŸå§‹è®°å½•åˆ—è¡¨
            
        Returns:
            å»é‡åçš„è®°å½•åˆ—è¡¨
        """
        if not records:
            return []
        
        # åŠ è½½å†å²æ•°æ®
        self._load_existing_data()
        
        self.logger.info(f"\nğŸ” å¼€å§‹å»é‡å¤„ç†: {len(records)} æ¡è®°å½•")
        
        unique_records = []
        seen_licenses = set(self._existing_licenses)
        seen_addresses = set(self._existing_addresses)
        seen_names_addresses = set()
        
        duplicates = {
            'license': 0,
            'name_address': 0,
            'fuzzy_address': 0
        }
        
        for record in records:
            license_number = record.get('license_number', '').strip()
            address = record.get('address', '').lower().strip()
            name = record.get('name', '').lower().strip()
            
            # 1. è®¸å¯è¯å·å»é‡
            if license_number:
                if license_number in seen_licenses:
                    duplicates['license'] += 1
                    continue
                seen_licenses.add(license_number)
            
            # 2. åç§°+åœ°å€ç»„åˆå»é‡
            name_address_key = f"{name}|{address}"
            if name_address_key in seen_names_addresses:
                duplicates['name_address'] += 1
                continue
            seen_names_addresses.add(name_address_key)
            
            # 3. åœ°å€æ¨¡ç³ŠåŒ¹é…å»é‡
            if address and self._is_similar_address(address, seen_addresses):
                duplicates['fuzzy_address'] += 1
                continue
            
            if address:
                seen_addresses.add(address)
            
            # é€šè¿‡æ‰€æœ‰å»é‡æ£€æŸ¥
            unique_records.append(record)
        
        # è¾“å‡ºå»é‡ç»Ÿè®¡
        total_duplicates = sum(duplicates.values())
        self.logger.info(f"ğŸ“Š å»é‡ç»“æœ:")
        self.logger.info(f"   - åŸå§‹è®°å½•: {len(records)} æ¡")
        self.logger.info(f"   - é‡å¤è®°å½•: {total_duplicates} æ¡")
        self.logger.info(f"     â”” è®¸å¯è¯é‡å¤: {duplicates['license']} æ¡")
        self.logger.info(f"     â”” åç§°+åœ°å€é‡å¤: {duplicates['name_address']} æ¡")
        self.logger.info(f"     â”” åœ°å€æ¨¡ç³Šé‡å¤: {duplicates['fuzzy_address']} æ¡")
        self.logger.info(f"   - å”¯ä¸€è®°å½•: {len(unique_records)} æ¡")
        
        return unique_records
    
    def _is_similar_address(self, address: str, existing_addresses: Set[str]) -> bool:
        """
        æ£€æŸ¥åœ°å€æ˜¯å¦ä¸å·²å­˜åœ¨çš„åœ°å€ç›¸ä¼¼
        
        Args:
            address: è¦æ£€æŸ¥çš„åœ°å€
            existing_addresses: å·²å­˜åœ¨çš„åœ°å€é›†åˆ
            
        Returns:
            æ˜¯å¦å­˜åœ¨ç›¸ä¼¼åœ°å€
        """
        if not address or not existing_addresses:
            return False
        
        # å¯¹äºå¤§é‡åœ°å€ï¼ŒåªæŠ½æ ·æ£€æŸ¥ä»¥æé«˜æ€§èƒ½
        addresses_to_check = existing_addresses
        if len(existing_addresses) > 1000:
            # å¦‚æœåœ°å€å¤ªå¤šï¼Œå…ˆåšç²¾ç¡®åŒ¹é…æ£€æŸ¥
            if address in existing_addresses:
                return True
            # ä¸åšæ¨¡ç³ŠåŒ¹é…ï¼ˆå¤ªè€—æ—¶ï¼‰
            return False
        
        for existing in addresses_to_check:
            # ä½¿ç”¨token_sort_ratioå¤„ç†è¯åºä¸åŒçš„æƒ…å†µ
            similarity = fuzz.token_sort_ratio(address, existing)
            if similarity >= self.ADDRESS_SIMILARITY_THRESHOLD:
                return True
        
        return False
    
    def dedupe_within_batch(self, records: List[Dict]) -> List[Dict]:
        """
        åœ¨å•ä¸ªæ‰¹æ¬¡å†…å»é‡ï¼ˆä¸ä¸å†å²æ•°æ®æ¯”è¾ƒï¼‰
        
        Args:
            records: è®°å½•åˆ—è¡¨
            
        Returns:
            å»é‡åçš„è®°å½•åˆ—è¡¨
        """
        if not records:
            return []
        
        unique_records = []
        seen_ids = set()
        
        for record in records:
            # ç”Ÿæˆå”¯ä¸€ID
            record_id = generate_record_id(record)
            
            if record_id not in seen_ids:
                seen_ids.add(record_id)
                unique_records.append(record)
        
        return unique_records
