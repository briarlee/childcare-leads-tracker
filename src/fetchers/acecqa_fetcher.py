"""
ACECQA National Registers æ•°æ®è·å–æ¨¡å—
è·å–æ¾³å¤§åˆ©äºšå¹¼å„¿æ•™è‚²å’ŒæŠ¤ç†æœåŠ¡æ³¨å†Œæ•°æ®
ä½¿ç”¨å®Œæ•´æµè§ˆå™¨å¤´æ¨¡æ‹Ÿç»•è¿‡403é™åˆ¶
"""

import re
import time
from typing import Dict, List, Optional
from datetime import datetime

import requests
import pandas as pd
from io import StringIO

from .base_fetcher import BaseFetcher
from utils.helpers import get_today


class ACECQAFetcher(BaseFetcher):
    """ACECQA National Registers æ•°æ®è·å–å™¨"""
    
    # ä¸»é¡µURL
    PAGE_URL = "https://www.acecqa.gov.au/resources/national-registers"
    
    # ç›´æ¥CSVä¸‹è½½URLsï¼ˆç”¨æˆ·æä¾›çš„å·¥ä½œé“¾æ¥ï¼‰
    DIRECT_CSV_URLS = [
        # å…¨æ¾³å¤§åˆ©äºšæœåŠ¡åˆ—è¡¨ï¼ˆä¸»URLï¼‰
        "https://www.acecqa.gov.au/sites/default/files/national-registers/services/Education-services-au-export.csv",
        # å¸¦nocacheå‚æ•°
        "https://www.acecqa.gov.au/sites/default/files/national-registers/services/Education-services-au-export.csv?nocache=1",
    ]
    
    # å®Œæ•´çš„æµè§ˆå™¨å¤´æ¨¡æ‹Ÿ
    BROWSER_HEADERS = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
        'Accept-Language': 'en-AU,en;q=0.9,en-US;q=0.8',
        'Accept-Encoding': 'gzip, deflate, br',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
        'Sec-Fetch-Dest': 'document',
        'Sec-Fetch-Mode': 'navigate',
        'Sec-Fetch-Site': 'none',
        'Sec-Fetch-User': '?1',
        'Cache-Control': 'max-age=0',
    }
    
    def __init__(self):
        super().__init__("ACECQA")
        self.status['type'] = 'CSV'
        self.session = requests.Session()
        self.session.headers.update(self.BROWSER_HEADERS)
    
    def fetch(self) -> List[Dict]:
        """è·å–ACECQAæ•°æ®"""
        self.logger.info(f"\n{'='*50}")
        self.logger.info(f"ğŸ‡¦ğŸ‡º å¼€å§‹è·å– ACECQA National Registers æ•°æ®")
        self.logger.info(f"{'='*50}")
        
        df = None
        
        # æ–¹æ³•1ï¼šå°è¯•ç›´æ¥CSV URLs
        for csv_url in self.DIRECT_CSV_URLS:
            self.logger.info(f"ğŸ“¥ å°è¯•ç›´æ¥ä¸‹è½½CSV: {csv_url[:60]}...")
            df = self._fetch_csv_with_session(csv_url)
            if df is not None:
                break
            time.sleep(1)  # é¿å…è¯·æ±‚è¿‡å¿«
        
        # æ–¹æ³•2ï¼šä»é¡µé¢åŠ¨æ€è·å–CSVé“¾æ¥
        if df is None:
            self.logger.info("ğŸ“¡ å°è¯•ä»é¡µé¢è·å–CSVé“¾æ¥...")
            csv_url = self._get_csv_download_url()
            if csv_url:
                df = self._fetch_csv_with_session(csv_url)
        
        # æ–¹æ³•3ï¼šä½¿ç”¨data.gov.auçš„å¤‡ç”¨æ•°æ®
        if df is None:
            self.logger.info("ğŸ“¡ å°è¯•ä» data.gov.au è·å–...")
            df = self._fetch_from_data_gov_au()
        
        if df is not None:
            records = self.transform(df)
            self.status['count'] = len(records)
            self.status['status'] = 'æ­£å¸¸'
            self.logger.info(f"ğŸ“Š ACECQAæ•°æ®å¤„ç†å®Œæˆ: {len(records)} æ¡è®°å½•")
            return records
        
        # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œè¿”å›ç©ºåˆ—è¡¨
        self.logger.warning("âš ï¸ æ— æ³•è·å–ACECQAæ•°æ®ï¼Œè¿”å›ç©ºåˆ—è¡¨")
        self.status['status'] = 'å¼‚å¸¸'
        self.status['error'] = 'æ‰€æœ‰æ•°æ®æºéƒ½æ— æ³•è®¿é—®'
        return []
    
    def _fetch_csv_with_session(self, url: str) -> Optional[pd.DataFrame]:
        """ä½¿ç”¨sessionè·å–CSV"""
        try:
            # é¦–å…ˆè®¿é—®ä¸»é¡µè·å–cookies
            try:
                self.session.get(self.PAGE_URL, timeout=10)
            except:
                pass
            
            # ç„¶åè·å–CSV
            response = self.session.get(url, timeout=30)
            response.raise_for_status()
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯CSVå†…å®¹
            content_type = response.headers.get('Content-Type', '')
            if 'text/html' in content_type and 'csv' not in content_type:
                self.logger.warning(f"   è¿”å›çš„æ˜¯HTMLè€ŒéCSV")
                return None
            
            # è§£æCSV
            df = pd.read_csv(StringIO(response.text))
            self.logger.info(f"âœ… ä¸‹è½½æˆåŠŸ: {len(df)} è¡Œæ•°æ®")
            return df
            
        except Exception as e:
            self.logger.warning(f"   ä¸‹è½½å¤±è´¥: {str(e)[:100]}")
            return None
    
    def _get_csv_download_url(self) -> Optional[str]:
        """ä»ACECQAé¡µé¢è·å–CSVä¸‹è½½é“¾æ¥"""
        try:
            response = self.session.get(self.PAGE_URL, timeout=30)
            response.raise_for_status()
            
            from bs4 import BeautifulSoup
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # æŸ¥æ‰¾CSVä¸‹è½½é“¾æ¥
            for link in soup.find_all('a', href=True):
                href = link['href']
                text = link.get_text().lower()
                
                if '.csv' in href.lower() and ('service' in text or 'australia' in text or 'export' in href.lower()):
                    if href.startswith('http'):
                        return href
                    else:
                        return f"https://www.acecqa.gov.au{href}"
            
            # æŸ¥æ‰¾ä»»ä½•CSVé“¾æ¥
            for link in soup.find_all('a', href=True):
                if '.csv' in link['href'].lower():
                    href = link['href']
                    if href.startswith('http'):
                        return href
                    else:
                        return f"https://www.acecqa.gov.au{href}"
            
            return None
            
        except Exception as e:
            self.logger.warning(f"   è·å–é¡µé¢å¤±è´¥: {str(e)[:100]}")
            return None
    
    def _fetch_from_data_gov_au(self) -> Optional[pd.DataFrame]:
        """ä»æ¾³å¤§åˆ©äºšæ”¿åºœå¼€æ”¾æ•°æ®é—¨æˆ·è·å–æ•°æ®"""
        try:
            # data.gov.au ä¸Šçš„ACECQAæ•°æ®
            api_url = "https://data.gov.au/data/api/3/action/datastore_search"
            params = {
                'resource_id': 'your-resource-id-here',  # éœ€è¦æ‰¾åˆ°æ­£ç¡®çš„resource_id
                'limit': 10000
            }
            
            response = requests.get(api_url, params=params, timeout=30)
            if response.status_code == 200:
                data = response.json()
                if data.get('success') and data.get('result', {}).get('records'):
                    return pd.DataFrame(data['result']['records'])
            
            return None
            
        except Exception as e:
            self.logger.warning(f"   data.gov.au è·å–å¤±è´¥: {str(e)[:100]}")
            return None
    
    def transform(self, df: pd.DataFrame) -> List[Dict]:
        """è½¬æ¢DataFrameä¸ºæ ‡å‡†è®°å½•æ ¼å¼"""
        records = []
        columns = df.columns.tolist()
        
        self.logger.debug(f"   CSVåˆ—: {columns[:10]}...")
        
        # ACECQAåˆ—åæ˜ å°„ï¼ˆæ ¹æ®å®é™…CSVï¼‰
        column_mapping = {
            'name': self._find_column(columns, ['ServiceName', 'Service Name']),
            'provider': self._find_column(columns, ['ProviderLegalName', 'Provider Name']),
            'address': self._find_column(columns, ['ServiceAddress', 'Address']),
            'suburb': self._find_column(columns, ['Suburb', 'City']),
            'state': self._find_column(columns, ['State', 'State/Territory']),
            'postcode': self._find_column(columns, ['Postcode', 'Post Code']),
            'phone': self._find_column(columns, ['Phone', 'Telephone']),
            'service_type': self._find_column(columns, ['ServiceType', 'Service Type']),
            'approval_number': self._find_column(columns, ['ServiceApprovalNumber', 'Approval Number']),
            'quality_rating': self._find_column(columns, ['OverallRating', 'Overall Rating']),
            'approved_places': self._find_column(columns, ['NumberOfApprovedPlaces', 'Approved Places']),
            'approval_date': self._find_column(columns, ['ServiceApprovalGrantedDate', 'Approval Date']),
        }
        
        for _, row in df.iterrows():
            try:
                name = self._safe_get(row, column_mapping['name'])
                if not name:
                    continue
                
                # æ„å»ºå®Œæ•´åœ°å€
                address = self._safe_get(row, column_mapping['address'])
                suburb = self._safe_get(row, column_mapping['suburb'])
                state = self._safe_get(row, column_mapping['state'])
                postcode = self._safe_get(row, column_mapping['postcode'])
                
                address_parts = [p for p in [address, suburb, state, postcode] if p]
                full_address = ', '.join(address_parts)
                
                # è§£æå®¹é‡
                capacity = self._safe_get(row, column_mapping['approved_places'])
                try:
                    capacity = int(float(str(capacity).replace(',', ''))) if capacity else None
                except (ValueError, TypeError):
                    capacity = None
                
                record = {
                    'name': str(name).strip(),
                    'license_holder': self._safe_get(row, column_mapping['provider']),
                    'address': full_address,
                    'city': str(suburb).strip() if suburb else '',
                    'province': self._normalize_state(state),
                    'country': 'Australia',
                    'license_number': self._safe_get(row, column_mapping['approval_number']),
                    'capacity': capacity,
                    'phone': self._safe_get(row, column_mapping['phone']),
                    'email': None,  # ACECQAæ•°æ®ä¸åŒ…å«é‚®ç®±
                    'service_type': self._safe_get(row, column_mapping['service_type']),
                    'quality_rating': self._safe_get(row, column_mapping['quality_rating']),
                    'license_status': 'å·²æ‰¹å‡†',
                    'discovered_date': get_today(),
                    'source': 'ACECQA National Register',
                    'source_url': self.PAGE_URL,
                    'type': 'æ–°å»º',
                }
                
                records.append(record)
                
            except Exception as e:
                self.logger.debug(f"   è·³è¿‡ä¸€æ¡è®°å½•: {str(e)}")
                continue
        
        return records
    
    def _normalize_state(self, state: str) -> str:
        """æ ‡å‡†åŒ–æ¾³å¤§åˆ©äºšå·å"""
        if not state:
            return ''
        
        state_mapping = {
            'nsw': 'New South Wales',
            'vic': 'Victoria',
            'qld': 'Queensland',
            'wa': 'Western Australia',
            'sa': 'South Australia',
            'tas': 'Tasmania',
            'act': 'Australian Capital Territory',
            'nt': 'Northern Territory',
            'new south wales': 'New South Wales',
            'victoria': 'Victoria',
            'queensland': 'Queensland',
            'western australia': 'Western Australia',
            'south australia': 'South Australia',
            'tasmania': 'Tasmania',
            'australian capital territory': 'Australian Capital Territory',
            'northern territory': 'Northern Territory'
        }
        
        state_lower = state.lower().strip()
        return state_mapping.get(state_lower, state)
    
    def _find_column(self, columns: List[str], possible_names: List[str]) -> Optional[str]:
        """æŸ¥æ‰¾åŒ¹é…çš„åˆ—å"""
        for name in possible_names:
            if name in columns:
                return name
            for col in columns:
                if col.lower() == name.lower():
                    return col
        return None
    
    def _safe_get(self, row, column: str):
        """å®‰å…¨è·å–è¡Œä¸­çš„å€¼"""
        if column is None:
            return None
        try:
            value = row.get(column)
            if pd.isna(value):
                return None
            return str(value).strip() if value else None
        except:
            return None
    
    def fetch_new_services(self, existing_approvals: set = None) -> List[Dict]:
        """è·å–æ–°æœåŠ¡"""
        all_records = self.fetch()
        
        if existing_approvals is None or len(existing_approvals) == 0:
            return all_records
        
        new_records = [
            r for r in all_records
            if r.get('license_number') and r['license_number'] not in existing_approvals
        ]
        
        self.logger.info(f"ğŸ” è¿‡æ»¤åæ–°è®°å½•: {len(new_records)} æ¡")
        self.status['count'] = len(new_records)
        
        return new_records
