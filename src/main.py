"""
å¹¼å„¿å›­å•†æœºè‡ªåŠ¨è¿½è¸ªç³»ç»Ÿ - ä¸»ç¨‹åºå…¥å£
æ¯æ—¥ä»åŠ æ‹¿å¤§å’Œæ¾³å¤§åˆ©äºšæ”¿åºœæ•°æ®æºè·å–å¹¼å„¿å›­å•†æœºï¼Œ
è¿›è¡Œæ™ºèƒ½åˆ†æåå†™å…¥Google Sheetsï¼Œå¹¶é€šè¿‡åŒæ¸ é“æ¨é€é€šçŸ¥ã€‚
"""

import os
import sys
from datetime import datetime
from pathlib import Path

# æ·»åŠ srcåˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv(Path(__file__).parent.parent / '.env')

from config import config
from core.sheets_manager import SheetsManager
from core.data_processor import DataProcessor
from fetchers.ontario_fetcher import OntarioFetcher
from fetchers.bc_fetcher import BCFetcher
from fetchers.acecqa_fetcher import ACECQAFetcher
from analyzers.deduplicator import Deduplicator
from analyzers.claude_analyzer import ClaudeAnalyzer
from analyzers.scorer import Scorer
from notifiers.notification_manager import NotificationManager
from utils.logger import setup_logger


def main():
    """ä¸»ç¨‹åºå…¥å£"""
    
    # åˆå§‹åŒ–æ—¥å¿—
    logger = setup_logger()
    
    logger.info("=" * 60)
    logger.info("ğŸš€ å¹¼å„¿å›­å•†æœºè‡ªåŠ¨è¿½è¸ªç³»ç»Ÿå¯åŠ¨")
    logger.info(f"â° è¿è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info("=" * 60)
    
    # æ‰“å°é…ç½®ä¿¡æ¯
    if config.DEBUG_MODE:
        config.print_config()
    
    # éªŒè¯é…ç½®
    errors = config.validate()
    if errors:
        for error in errors:
            logger.error(f"âŒ é…ç½®é”™è¯¯: {error}")
        if not config.DRY_RUN:
            sys.exit(1)
    
    try:
        # 1. åˆå§‹åŒ–å„æ¨¡å—
        logger.info("\nğŸ“¦ åˆå§‹åŒ–æ¨¡å—...")
        
        sheets = None
        if not config.DRY_RUN:
            try:
                sheets = SheetsManager()
            except Exception as e:
                logger.error(f"âŒ Google Sheetsåˆå§‹åŒ–å¤±è´¥: {str(e)}")
                logger.info("â„¹ï¸ ç»§ç»­è¿è¡Œä½†ä¸ä¼šå†™å…¥Sheets")
        
        processor = DataProcessor()
        deduplicator = Deduplicator(sheets)
        
        # æ ¹æ®é…ç½®é€‰æ‹©è¯„åˆ†å™¨
        if config.ENABLE_CLAUDE_AI:
            analyzer = ClaudeAnalyzer()
        else:
            analyzer = Scorer()
        
        notifier = NotificationManager()
        
        # 2. è·å–å¯ç”¨çš„æ•°æ®æº
        enabled_sources = [s.strip().lower() for s in config.ENABLED_SOURCES]
        logger.info(f"\nğŸ“¡ å¯ç”¨çš„æ•°æ®æº: {', '.join(enabled_sources)}")
        
        all_records = []
        source_status = []
        
        # 3. ä»å„æ•°æ®æºè·å–æ•°æ®
        logger.info("\nğŸ“¥ å¼€å§‹è·å–æ•°æ®...")
        
        # Ontarioæ•°æ®æº
        if 'ontario' in enabled_sources:
            try:
                logger.info("\nğŸ‡¨ğŸ‡¦ è·å–Ontarioæ•°æ®...")
                ontario = OntarioFetcher()
                ontario_data = ontario.fetch()
                logger.info(f"   âœ… Ontario: è·å– {len(ontario_data)} æ¡è®°å½•")
                all_records.extend(ontario_data)
                source_status.append(ontario.get_status())
            except Exception as e:
                logger.error(f"   âŒ Ontarioè·å–å¤±è´¥: {str(e)}")
                source_status.append({
                    'name': 'Ontario Open Data',
                    'status': 'å¼‚å¸¸',
                    'error': str(e),
                    'count': 0
                })
        
        # BCæ•°æ®æº
        if 'bc' in enabled_sources:
            try:
                logger.info("\nğŸ‡¨ğŸ‡¦ è·å–BCæ•°æ®...")
                bc = BCFetcher()
                bc_data = bc.fetch()
                logger.info(f"   âœ… BC: è·å– {len(bc_data)} æ¡è®°å½•")
                all_records.extend(bc_data)
                source_status.append(bc.get_status())
            except Exception as e:
                logger.error(f"   âŒ BCè·å–å¤±è´¥: {str(e)}")
                source_status.append({
                    'name': 'BC Child Care',
                    'status': 'å¼‚å¸¸',
                    'error': str(e),
                    'count': 0
                })
        
        # ACECQAæ•°æ®æº
        if 'acecqa' in enabled_sources:
            try:
                logger.info("\nğŸ‡¦ğŸ‡º è·å–ACECQAæ•°æ®...")
                acecqa = ACECQAFetcher()
                acecqa_data = acecqa.fetch()
                logger.info(f"   âœ… ACECQA: è·å– {len(acecqa_data)} æ¡è®°å½•")
                all_records.extend(acecqa_data)
                source_status.append(acecqa.get_status())
            except Exception as e:
                logger.error(f"   âŒ ACECQAè·å–å¤±è´¥: {str(e)}")
                source_status.append({
                    'name': 'ACECQA',
                    'status': 'å¼‚å¸¸',
                    'error': str(e),
                    'count': 0
                })
        
        logger.info(f"\nğŸ“Š æ€»è®¡è·å–: {len(all_records)} æ¡åŸå§‹è®°å½•")
        
        # 4. æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®
        if len(all_records) == 0:
            logger.info("\nâ„¹ï¸ ä»Šæ—¥æš‚æ— æ–°å¢è®°å½•")
            
            # å‘é€ç©ºæ‘˜è¦é€šçŸ¥
            summary_data = {
                'date': datetime.now().strftime('%Y-%m-%d'),
                'canada': {'new_projects': 0, 'sales': 0, 'tenders': 0},
                'australia': {'new_projects': 0, 'sales': 0, 'tenders': 0},
                'high_priority': [],
                'sources': source_status,
                'sheets_url': sheets.get_sheet_url() if sheets else config.GOOGLE_SHEET_URL,
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
            notifier.send_daily_summary(summary_data)
            
            logger.info("\nâœ… ç³»ç»Ÿè¿è¡Œå®Œæˆï¼ˆæ— æ–°æ•°æ®ï¼‰")
            return
        
        # 5. æ•°æ®å¤„ç†
        logger.info("\nğŸ”§ å¤„ç†æ•°æ®...")
        processed_records = processor.process_records(all_records)
        
        # 6. å»é‡
        logger.info("\nğŸ” æ‰§è¡Œå»é‡æ£€æµ‹...")
        unique_records = deduplicator.remove_duplicates(processed_records)
        
        if len(unique_records) == 0:
            logger.info("\nâ„¹ï¸ å»é‡åæ— æ–°å¢è®°å½•")
            
            summary_data = {
                'date': datetime.now().strftime('%Y-%m-%d'),
                'canada': {'new_projects': 0, 'sales': 0, 'tenders': 0},
                'australia': {'new_projects': 0, 'sales': 0, 'tenders': 0},
                'high_priority': [],
                'sources': source_status,
                'sheets_url': sheets.get_sheet_url() if sheets else config.GOOGLE_SHEET_URL,
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
            notifier.send_daily_summary(summary_data)
            
            logger.info("\nâœ… ç³»ç»Ÿè¿è¡Œå®Œæˆï¼ˆæ— æ–°æ•°æ®ï¼‰")
            return
        
        # 7. é™åˆ¶è®°å½•æ•°
        if len(unique_records) > config.MAX_RECORDS_PER_RUN:
            logger.warning(f"âš ï¸ è®°å½•æ•°è¶…è¿‡é™åˆ¶({config.MAX_RECORDS_PER_RUN})ï¼Œå°†æˆªæ–­")
            unique_records = unique_records[:config.MAX_RECORDS_PER_RUN]
        
        # 8. è¯„åˆ†
        logger.info("\nğŸ¤– å¼€å§‹æ™ºèƒ½è¯„åˆ†...")
        scored_records = analyzer.batch_score(unique_records)
        
        # 9. æŒ‰ä¼˜å…ˆçº§åˆ†ç±»
        critical_leads = [l for l in scored_records if l.get('priority') == 'Critical']
        high_leads = [l for l in scored_records if l.get('priority') == 'High']
        medium_leads = [l for l in scored_records if l.get('priority') == 'Medium']
        low_leads = [l for l in scored_records if l.get('priority') == 'Low']
        
        logger.info(f"\nğŸ“ˆ ä¼˜å…ˆçº§åˆ†å¸ƒ:")
        logger.info(f"   ğŸš¨ Critical: {len(critical_leads)} æ¡")
        logger.info(f"   ğŸ”¥ High: {len(high_leads)} æ¡")
        logger.info(f"   ğŸ“Œ Medium: {len(medium_leads)} æ¡")
        logger.info(f"   ğŸ“‹ Low: {len(low_leads)} æ¡")
        
        # 10. å†™å…¥Google Sheets
        if sheets:
            logger.info("\nğŸ’¾ å†™å…¥Google Sheets...")
            
            # åˆ†ç±»è®°å½•
            classified = processor.classify_records(scored_records)
            
            # å†™å…¥å„å·¥ä½œè¡¨
            sheets.append_new_projects(classified['new_projects'])
            sheets.append_sales(classified['sales'])
            sheets.append_tenders(classified['tenders'])
            
            # æ›´æ–°æ•°æ®æºç›‘æ§
            sheets.update_source_monitoring(source_status)
            
            # æ›´æ–°æ¯æ—¥ç»Ÿè®¡
            stats = processor.get_statistics(scored_records)
            stats['status'] = 'æ­£å¸¸'
            sheets.update_daily_stats(stats)
            
            logger.info(f"   âœ… æ•°æ®å·²ä¿å­˜åˆ°Google Sheets")
        
        # 11. å‘é€å³æ—¶é€šçŸ¥ï¼ˆCriticalå’ŒHighï¼‰
        logger.info("\nğŸ“± å‘é€å³æ—¶é€šçŸ¥...")
        notification_stats = notifier.process_scored_leads(scored_records)
        
        logger.info(f"   ğŸš¨ å·²å‘é€ç´§æ€¥é€šçŸ¥: {notification_stats['critical_notified']} æ¡")
        logger.info(f"   ğŸ”¥ å·²å‘é€é«˜ä¼˜å…ˆçº§é€šçŸ¥: {notification_stats['high_notified']} æ¡")
        
        # 12. ç”Ÿæˆå¹¶å‘é€æ¯æ—¥æ‘˜è¦
        logger.info("\nğŸ“Š ç”Ÿæˆæ¯æ—¥æ‘˜è¦...")
        
        stats = processor.get_statistics(scored_records)
        
        summary_data = {
            'date': datetime.now().strftime('%Y-%m-%d'),
            'canada': {
                'new_projects': stats['canada_new'],
                'sales': stats['canada_sales'],
                'tenders': stats['canada_tenders']
            },
            'australia': {
                'new_projects': stats['australia_new'],
                'sales': stats['australia_sales'],
                'tenders': stats['australia_tenders']
            },
            'high_priority': sorted(
                critical_leads + high_leads,
                key=lambda x: x.get('ai_score', 0),
                reverse=True
            )[:5],
            'sources': source_status,
            'sheets_url': sheets.get_sheet_url() if sheets else config.GOOGLE_SHEET_URL,
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
        
        notifier.send_daily_summary(summary_data)
        logger.info("   âœ… æ¯æ—¥æ‘˜è¦å·²å‘é€")
        
        # 13. å®Œæˆ
        logger.info("\n" + "=" * 60)
        logger.info("âœ… ç³»ç»Ÿè¿è¡Œå®Œæˆï¼")
        logger.info(f"ğŸ“Š æ€»ç»“:")
        logger.info(f"   - è·å–è®°å½•: {len(all_records)} æ¡")
        logger.info(f"   - å»é‡å: {len(unique_records)} æ¡")
        logger.info(f"   - é«˜ä»·å€¼å•†æœº: {len(critical_leads) + len(high_leads)} æ¡")
        logger.info("=" * 60)
        
    except Exception as e:
        logger.error(f"\nâŒ ç³»ç»Ÿè¿è¡Œå‡ºé”™: {str(e)}")
        logger.exception(e)
        
        # å‘é€é”™è¯¯é€šçŸ¥
        try:
            notifier = NotificationManager()
            notifier.send_error_alert(str(e), "ç³»ç»Ÿä¸»ç¨‹åº")
        except:
            pass
        
        sys.exit(1)


if __name__ == '__main__':
    main()
